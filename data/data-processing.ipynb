{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-kanji Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read JSON file and remove all unnecessary columns\n",
    "df = pd.read_json('kanji-individual.json') \\\n",
    "    .transpose() \\\n",
    "    .reset_index(names='kanji') \\\n",
    "    .drop(columns=[\n",
    "        'strokes', 'grade', 'freq', 'jlpt_old', 'jlpt_new', 'meanings', 'wk_level',\n",
    "        'wk_meanings', 'wk_radicals', 'wk_readings_on', 'wk_readings_kun'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kanji</th>\n",
       "      <th>readings_on</th>\n",
       "      <th>readings_kun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>瀾</td>\n",
       "      <td>[らん]</td>\n",
       "      <td>[なみ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>鰢</td>\n",
       "      <td>[ば, め]</td>\n",
       "      <td>[うみえび, つくら, すばしり]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>熅</td>\n",
       "      <td>[うん, おん]</td>\n",
       "      <td>[うずみび, いき.れ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>侗</td>\n",
       "      <td>[とう, つ, ず]</td>\n",
       "      <td>[おろ.か, いた.む, かたち, なおい, まこと, つつし.む]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>瓚</td>\n",
       "      <td>[さん]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kanji readings_on                        readings_kun\n",
       "4428      瀾        [らん]                                [なみ]\n",
       "11916     鰢      [ば, め]                   [うみえび, つくら, すばしり]\n",
       "8802      熅    [うん, おん]                        [うずみび, いき.れ]\n",
       "6458      侗  [とう, つ, ず]  [おろ.か, いた.む, かたち, なおい, まこと, つつし.む]\n",
       "9066      瓚        [さん]                                  []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kanji           0\n",
       "readings_on     0\n",
       "readings_kun    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the resulting dataset has no nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [\n",
    "    {'from': ord(u'\\u3040'), 'to': ord(u'\\u309f')},     # Hiragana\n",
    "    {\"from\": ord(u\"\\u30a0\"), \"to\": ord(u\"\\u30ff\")},     # Katakana\n",
    "]\n",
    "\n",
    "def is_hira_kata(char):\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in ranges])\n",
    "\n",
    "def is_kanji(char):\n",
    "    return not is_hira_kata(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['vocab-1-raw.xlsx', 'vocab-2-raw.xlsx', 'vocab-3-raw.xlsx']\n",
    "pages = ['重要度順語彙リスト60894語', '想定既知語彙リスト（固有名詞など）', '使用範囲狭小語彙リスト（想定既知語彙除く）']\n",
    "allWords = pd.DataFrame()\n",
    "\n",
    "for file, page in zip(files, pages):\n",
    "    wordsFile = pd.ExcelFile(file)\n",
    "    words = pd.read_excel(wordsFile, page)\n",
    "    words = words[['見出し語彙素\\nLexeme', '標準的（新聞）表記\\nStandard (Newspaper) Orthography', '標準的読み方（カタカナ）\\nStandard Reading (Katakana)']]\n",
    "    words.columns = ['word', 'orthography', 'reading']\n",
    "\n",
    "    allWords = pd.concat([allWords, words])\n",
    "\n",
    "# Make separate rows where 'word' and 'orthography' do not match\n",
    "allWords['combined'] = list(zip(allWords.word, allWords.orthography))\n",
    "wordsExpanded = allWords \\\n",
    "    .explode('combined', ignore_index=True) \\\n",
    "    .drop(columns=['word', 'orthography']) \\\n",
    "    .dropna(subset='reading') \\\n",
    "    .drop_duplicates() \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .rename(columns={'combined': 'word'}) \\\n",
    "    [['word', 'reading']]\n",
    "\n",
    "# Remove rows with number in the 'reading' column\n",
    "wordsExpanded = wordsExpanded[\n",
    "    (wordsExpanded.reading.str.isnumeric() == False) & \\\n",
    "    (wordsExpanded.word.str.isnumeric() == False)\n",
    "]\n",
    "\n",
    "# Remove rows with * in the 'word' column\n",
    "wordsExpanded = wordsExpanded[wordsExpanded.word.str.contains('＊') == False]\n",
    "\n",
    "# Remove rows with non-Kanji characters in the 'word' column\n",
    "wordsExpanded = wordsExpanded[~wordsExpanded.word.apply(lambda x: all([is_hira_kata(char) for char in x]))]\n",
    "wordsExpanded = wordsExpanded[~wordsExpanded.word.apply(lambda x: any([ord(char) in range(ord('a'), ord('z')) for char in x]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to SmoothKen from StackOverflow for the Hiragana-Katakana conversion\n",
    "# https://stackoverflow.com/questions/4877139/how-can-i-convert-all-japanese-hiragana-to-katakana-characters-in-python\n",
    "\n",
    "hira_start = int(\"3041\", 16)\n",
    "hira_end = int(\"3096\", 16)\n",
    "kata_start = int(\"30a1\", 16)\n",
    "\n",
    "kata_to_hira = dict()\n",
    "for i in range(hira_start, hira_end+1):\n",
    "    kata_to_hira[chr(i-hira_start+kata_start)] = chr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert katakana to hiragana\n",
    "wordsExpanded['reading_hira'] = wordsExpanded.reading.apply(lambda x: ''.join([kata_to_hira.get(char, char) for char in x]))\n",
    "wordsExpanded = wordsExpanded.drop(columns='reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsExpanded.to_csv('vocab-expanded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>reading_hira</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12421</th>\n",
       "      <td>占有</td>\n",
       "      <td>せんゆう</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40213</th>\n",
       "      <td>御酒</td>\n",
       "      <td>みき</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39116</th>\n",
       "      <td>切り出し</td>\n",
       "      <td>きりだし</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14415</th>\n",
       "      <td>捏造</td>\n",
       "      <td>ねつぞう</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92153</th>\n",
       "      <td>ｎｏａａ</td>\n",
       "      <td>のあ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37305</th>\n",
       "      <td>反軍</td>\n",
       "      <td>はんぐん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21971</th>\n",
       "      <td>漢語</td>\n",
       "      <td>かんご</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33782</th>\n",
       "      <td>物入れ</td>\n",
       "      <td>ものいれ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56062</th>\n",
       "      <td>気孔</td>\n",
       "      <td>きこう</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134679</th>\n",
       "      <td>蟹玉</td>\n",
       "      <td>かにたま</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54850</th>\n",
       "      <td>大切り</td>\n",
       "      <td>おおぎり</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151482</th>\n",
       "      <td>屋嘉</td>\n",
       "      <td>やか</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54065</th>\n",
       "      <td>必置</td>\n",
       "      <td>ひっち</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75370</th>\n",
       "      <td>中元</td>\n",
       "      <td>なかもと</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32832</th>\n",
       "      <td>食傷</td>\n",
       "      <td>しょくしょう</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>奇貨</td>\n",
       "      <td>きか</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22080</th>\n",
       "      <td>海抜</td>\n",
       "      <td>かいばつ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33047</th>\n",
       "      <td>弁理</td>\n",
       "      <td>べんり</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57113</th>\n",
       "      <td>涼感</td>\n",
       "      <td>りょうかん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22172</th>\n",
       "      <td>凍てる</td>\n",
       "      <td>いてる</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word reading_hira\n",
       "12421     占有         せんゆう\n",
       "40213     御酒           みき\n",
       "39116   切り出し         きりだし\n",
       "14415     捏造         ねつぞう\n",
       "92153   ｎｏａａ           のあ\n",
       "37305     反軍         はんぐん\n",
       "21971     漢語          かんご\n",
       "33782    物入れ         ものいれ\n",
       "56062     気孔          きこう\n",
       "134679    蟹玉         かにたま\n",
       "54850    大切り         おおぎり\n",
       "151482    屋嘉           やか\n",
       "54065     必置          ひっち\n",
       "75370     中元         なかもと\n",
       "32832     食傷       しょくしょう\n",
       "51198     奇貨           きか\n",
       "22080     海抜         かいばつ\n",
       "33047     弁理          べんり\n",
       "57113     涼感        りょうかん\n",
       "22172    凍てる          いてる"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsExpanded.sample(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
